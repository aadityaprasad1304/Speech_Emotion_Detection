{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550b097-89e7-4510-8821-d6bf5ac62e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2009d0-8bfa-4aeb-9919-79c00f9c6753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adityaprasad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 5000)\n"
     ]
    }
   ],
   "source": [
    "import re  # Regular expressions\n",
    "import nltk  # Natural Language Toolkit for text processing\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "from sklearn.model_selection import train_test_split  # Splitting data into train and test sets\n",
    "from sklearn.neural_network import MLPClassifier  # Multi-layer Perceptron classifier\n",
    "from sklearn.preprocessing import LabelEncoder  # Encoding labels\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score  # Model evaluation metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Text vectorization\n",
    "import pyaudio  # Audio input\n",
    "import numpy as np  # Numerical operations\n",
    "import speech_recognition as sr  # Speech recognition library\n",
    "\n",
    "# Load NLTK stopwords (common words to be removed from text)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load your dataset from a CSV file named 'training.csv'\n",
    "dataset = pd.read_csv('training.csv')\n",
    "\n",
    "# Initialize an empty list to store processed text\n",
    "corpus = []\n",
    "\n",
    "# Loop through each row in the dataset\n",
    "for i in range(len(dataset)):\n",
    "    text = str(dataset.iloc[i, 0])  # Extract the text from the first column\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text).lower()  # Remove non-alphabet characters and convert to lowercase\n",
    "    words = text.split()  # Split the text into words\n",
    "    text = ' '.join(words)  # Join the words back into a string\n",
    "    corpus.append(text)  # Append the processed text to the corpus list\n",
    "\n",
    "# Store the processed text in a variable\n",
    "processed_text = corpus\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use TF-IDF Vectorization with a limited number of features (e.g., 5000)\n",
    "max_features = 5000\n",
    "vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "X = vectorizer.fit_transform(processed_text).toarray()\n",
    "print(X.shape)\n",
    "\n",
    "# Extract emotion labels from the dataset\n",
    "emotion_detection_y = dataset.iloc[:, 1].values\n",
    "\n",
    "# Encode the emotion labels into numerical format\n",
    "le = LabelEncoder()\n",
    "emotion_detection_y = le.fit_transform(emotion_detection_y)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, emotion_detection_y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60e460-c406-4dcf-8b5f-f7e7e078dbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae2d6be-7fec-47c6-9909-27c3c7532aac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[799  36   7  44  17   2]\n",
      " [ 37 930  58  14  10   4]\n",
      " [  9  63 188   5   6   0]\n",
      " [ 45  16   2 382  14   0]\n",
      " [ 34  26  10  37 275  15]\n",
      " [ 10  14   2   0   8  81]]\n",
      "Accuracy Score: 0.8296875\n",
      "Precision Score: 0.8061175322488671\n"
     ]
    }
   ],
   "source": [
    "# Create a Multi-layer Perceptron (MLP) classifier with 2 hidden layers (100 neurons, 50 neurons)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, random_state=0)\n",
    "\n",
    "# Train the MLP classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the confusion matrix and accuracy score\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "pre_score = precision_score(y_test, y_pred, average = \"macro\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy Score:\", acc_score)\n",
    "print(\"Precision Score:\", pre_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe7575-259b-40d1-a516-3d8d6bc258ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75568d98-02c1-4e3a-815a-54848cd9df28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Finished recording.\n",
      "Audio to Text: I love you try something else I am disappointed\n"
     ]
    }
   ],
   "source": [
    "# Initialize PyAudio for audio input\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Define audio capture parameters\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 5\n",
    "\n",
    "# Start the audio stream\n",
    "stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "print(\"Listening...\")\n",
    "\n",
    "# Record audio for a specified duration\n",
    "frames = []\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "# Stop and close the audio stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "# Process the live audio by converting it to a NumPy array\n",
    "live_audio = np.frombuffer(b''.join(frames), dtype=np.int16)\n",
    "\n",
    "# Use SpeechRecognition to transcribe the audio to text\n",
    "recognizer = sr.Recognizer()\n",
    "live_audio_data = sr.AudioData(live_audio.tobytes(), RATE, live_audio.dtype.itemsize)\n",
    "\n",
    "# Recognize the audio and convert it to text using Google Speech Recognition\n",
    "try:\n",
    "    recognized_text = recognizer.recognize_google(live_audio_data)\n",
    "    print(\"Audio to Text:\", recognized_text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "\n",
    "# Convert the live text to a numerical format using TF-IDF Vectorizer\n",
    "live_vector = vectorizer.transform([recognized_text]).toarray()\n",
    "#print(\"Live Vector:\", live_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedaee1f-94dd-4099-83bd-b3915d63bb25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c9543c7-63f5-4484-841a-8d3ca4d78fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion: sad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data_dict = {\\'text\\': [recognized_text], \\'label\\': [predicted_emotion]}\\n\\n# Create a DataFrame from the dictionary\\nnew_data_df = pd.DataFrame(data_dict)\\n\\n# Append the new data to the original dataset\\nupdated_dataset = pd.concat([dataset, new_data_df], ignore_index=True)\\n\\n# Save the updated DataFrame to the CSV file\\nupdated_dataset.to_csv(\\'training.csv\\', index=False)\\n\\nprint(\"Updated dataset saved to training.csv.\")'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Predict the emotion label for the live audio using the trained classifier\n",
    "predicted_labels = clf.predict(live_vector)\n",
    "\n",
    "# Define a mapping of predicted labels to emotions\n",
    "emotion_mapping = {\n",
    "    0: \"sad\",\n",
    "    1: \"joy\",\n",
    "    2: \"love\",\n",
    "    3: \"anger\",\n",
    "    4: \"fear\",\n",
    "    5: \"surprise\"\n",
    "}\n",
    "\n",
    "# Map the predicted label to the corresponding emotion\n",
    "predicted_emotion = emotion_mapping.get(predicted_labels[0], \"Unknown\")\n",
    "\n",
    "# Print the predicted emotion\n",
    "print(\"Predicted Emotion:\", predicted_emotion)\n",
    "\n",
    "# Create a dictionary with recognized_text as keys and predicted_emotion as values\n",
    "'''data_dict = {'text': [recognized_text], 'label': [predicted_emotion]}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "new_data_df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Append the new data to the original dataset\n",
    "updated_dataset = pd.concat([dataset, new_data_df], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame to the CSV file\n",
    "updated_dataset.to_csv('training.csv', index=False)\n",
    "\n",
    "print(\"Updated dataset saved to training.csv.\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe701e-b662-4005-802f-dcf1af16874f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
